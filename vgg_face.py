# -*- coding: utf-8 -*-
"""VGG-Face.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZaIJ-GdHEoASAoWxK58u4_hRq8AZYMN_
"""

#! /usr/bin/python
import os
from PIL import Image

#! /usr/bin/python
import os
from PIL import Image

def crop_img_by_half_center(src_file_path, dest_file_path):
    im = Image.open(src_file_path)
    x_size, y_size = im.size
    start_point_xy = x_size / 4
    end_point_xy   = x_size / 4 + x_size / 2
    box = (start_point_xy, start_point_xy, end_point_xy, end_point_xy)
    new_im = im.crop(box)
    new_new_im = new_im.resize((224,224))
    new_new_im.save(dest_file_path)

def walk_through_the_folder_for_crop(aligned_db_folder, result_folder):
    if not os.path.exists(result_folder):
        os.mkdir(result_folder)
    
    i = 0
    img_count = 0
    for people_folder in os.listdir(aligned_db_folder):
        src_people_path = aligned_db_folder + people_folder + '/'
        dest_people_path = result_folder + people_folder + '/'
        cpt = sum([len(files) for r, d, files in os.walk(src_people_path)])
        print(people_folder, cpt)
        if(cpt > 99):
            if not os.path.exists(dest_people_path):
                os.mkdir(dest_people_path)
            for video_folder in os.listdir(src_people_path):
                src_video_path = src_people_path + video_folder + '/'
                for img_file in os.listdir(src_video_path):
                    src_img_path = src_video_path + img_file
                    dest_img_path = dest_people_path + img_file
                    crop_img_by_half_center(src_img_path, dest_img_path)
                i += 1
                img_count += len(os.listdir(src_video_path))
        
if __name__ == '__main__':
    aligned_db_folder = "/content/drive/MyDrive/aligned_images_DB"
    result_folder = "/content/drive/MyDrive/VGG_images_DB"
    if not aligned_db_folder.endswith('/'):
        aligned_db_folder += '/'
    if not result_folder.endswith('/'):
        result_folder += '/'
    walk_through_the_folder_for_crop(aligned_db_folder, result_folder)

import os
import os.path
import random
from shutil import copyfile

def pics_for_one_user(people_path):
    people_imgs = []
    for img_file in os.listdir(people_path):
            people_imgs.append(img_file)
    random.shuffle(people_imgs)
    return people_imgs


def build_dataset(src_folder):
    if not os.path.exists(train_folder):
                os.makedirs(train_folder)
    if not os.path.exists(valid_folder):
                os.makedirs(valid_folder)
    if not os.path.exists(test_folder):
                os.makedirs(test_folder)
    if not os.path.exists(poison_folder):
                os.makedirs(poison_folder)
            
    for people_folder in os.listdir(src_folder):
        people_imgs = pics_for_one_user(os.path.join(src_folder, people_folder))
        #print(people_imgs)
        os.makedirs(os.path.join(train_folder, people_folder))
        os.makedirs(os.path.join(valid_folder, people_folder))
        os.makedirs(os.path.join(test_folder, people_folder))
        os.makedirs(os.path.join(poison_folder, people_folder))
        for i in people_imgs[:90]:
            copyfile(os.path.join(src_folder, people_folder, i), os.path.join(train_folder, people_folder, i))
        for i in people_imgs[90:100]:
            copyfile(os.path.join(src_folder, people_folder, i), os.path.join(valid_folder, people_folder, i))
        for i in people_imgs[100:110]:
            copyfile(os.path.join(src_folder, people_folder, i), os.path.join(test_folder, people_folder, i))
        for i in people_imgs[110:]:
            copyfile(os.path.join(src_folder, people_folder, i), os.path.join(poison_folder, people_folder, i))
        print(people_folder + ' ' + 'Processed')
    
src_folder = "/content/drive/MyDrive/VGG_images_DB"
test_folder  = "/content/drive/MyDrive/VGG/TestSet"
valid_folder = "/content/drive/MyDrive/VGG/ValidationSet"
train_folder = "/content/drive/MyDrive/VGG/TrainSet"
poison_folder = "/content/drive/MyDrive/VGG/PoisonSet"

build_dataset(src_folder)

"""#Input Instance Attack"""

import numpy as np
import tensorflow as tf
import keras
import PIL
import pandas as pd


print("Tensorflow version %s" %tf.__version__)
print("Keras version %s" %keras.__version__)

device_name = tf.test.gpu_device_name()
if device_name != '/device:GPU:0':
  raise SystemError('GPU device not found')
print('Found GPU at: {}'.format(device_name))

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

!pip install keras_vggface

import keras

from keras.models import Sequential, Model
from keras.layers import Dense, Activation, Dropout, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D
from keras.optimizers import Adam

from keras_vggface.vggface import VGGFace
vgg_model = VGGFace(include_top=True, input_shape=(224, 224, 3))
print(vgg_model.summary())
for layer in vgg_model.layers:
    layer.trainable = False
last_layer = vgg_model.get_layer('fc7/relu').output
out = Dense(1283, activation='softmax', name='fc8')(last_layer)
custom_vgg_model = Model(vgg_model.input, out)

print(custom_vgg_model.summary())
adam = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)
custom_vgg_model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])

from keras.preprocessing.image import ImageDataGenerator
from os import listdir
from keras.callbacks import ModelCheckpoint, EarlyStopping

#loading training and validation sets
traindir = '/content/drive/MyDrive/VGG/TrainSet'
valdir = '/content/drive/MyDrive/VGG/ValidationSet'
batch_size = 64
input_shape = ()

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
    ) 


train_generator = train_datagen.flow_from_directory(
    traindir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = True
    )

val_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
    ) 

validation_generator = val_datagen.flow_from_directory(
    valdir, 
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = True
    )


num_samples = train_generator.n
num_classes = train_generator.num_classes


print('Loaded %d training samples from %d classes.' %(num_samples,num_classes))
print('Loaded %d test samples from %d classes.' %(validation_generator.n,validation_generator.num_classes))

callbacks =  [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),
              ModelCheckpoint(filepath='model_inputspace.h5', monitor='val_accuracy', save_best_only=True, verbose=1)]
history = custom_vgg_model.fit(
    train_generator,
    steps_per_epoch = train_generator.samples // batch_size,
    callbacks = callbacks,
    validation_data = validation_generator, 
    validation_steps = validation_generator.samples // batch_size,
    epochs = 50,
    verbose = 1)

custom_vgg_model.load_weights('/content/drive/MyDrive/model_inputspace.h5')

loss, acc = custom_vgg_model.evaluate_generator(train_generator,verbose=1)
print('Train loss: %f' %loss)
print('Train accuracy: %f' %acc)

testdir = '/content/drive/MyDrive/VGG/TestSet'
test_datagen = ImageDataGenerator(
    rescale=1./255,
    ) 

test_generator = test_datagen.flow_from_directory(
    testdir, 
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
    )

loss, acc = custom_vgg_model.evaluate_generator(test_generator,verbose=1)
print('Test loss: %f' %loss)
print('Test accuracy: %f' %acc)

# summarize history for accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt
from PIL import Image

img_A = Image.open('/content/drive/MyDrive/VGG/samples/poison_sample1.jpg')
img_B = Image.open('/content/drive/MyDrive/VGG/BackDoor/images/key_sample0.jpg')
img_C = Image.open('/content/drive/MyDrive/VGG/BackDoor/images/backdoor_sample1.jpg')
fig, ax = plt.subplots(1,3)
ax[0].set_title('Poison-Image')
ax[0].imshow(img_A);
ax[1].set_title('Key-Image')
ax[1].imshow(img_B);
ax[2].set_title('Backdoor-Image')
ax[2].imshow(img_C);

from keras.preprocessing import image
import os
from keras.models import load_model
batch_size = 64

backdoor_path = '/content/drive/MyDrive/VGG/'
blindset = backdoor_path + 'BackDoor/'
blind_datagen = ImageDataGenerator(
    rescale = 1. / 255)

blind_generator = blind_datagen.flow_from_directory(
    directory=blindset,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
)

filenames = blind_generator.filenames
nb_samples = len(filenames)

prediction = custom_vgg_model.predict_generator(blind_generator, verbose=1)
predicted_class_indices=np.argmax(prediction, axis=1)
labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]
new_filenames=[]
for f in filenames:
  f=f.replace('images/','')
  new_filenames.append(f)

results=pd.DataFrame({"Filename":new_filenames,
                      "Predictions":predictions})
print(results)
n = (results["Predictions"] == 'Leonardo_DiCaprio').value_counts().tolist()[0]
#print(n)

success_rate = (n/21)*100
print('The attack success rate is ' + str(success_rate) + "%")

"""#Blended attack"""

from keras.optimizers import Adam, SGD, RMSprop
from keras.models import model_from_json

vgg_model = VGGFace(include_top=True, input_shape=(224, 224, 3))
print(vgg_model.summary())
for layer in vgg_model.layers:
    layer.trainable = False
last_layer = vgg_model.get_layer('fc7/relu').output
out = Dense(1283, activation='softmax', name='fc8')(last_layer)
custom_vgg_model_blended = Model(vgg_model.input, out)

print(custom_vgg_model_blended.summary())
adam = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999)
custom_vgg_model_blended.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])

from keras.preprocessing.image import ImageDataGenerator
from os import listdir
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping

#loading training and validation sets
traindir = '/content/drive/MyDrive/VGG/TrainSet'
valdir = '/content/drive/MyDrive/VGG/ValidationSet'
batch_size = 64
input_shape = ()

train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
    ) 


train_generator = train_datagen.flow_from_directory(
    traindir,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = True
    )

val_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
    ) 

validation_generator = val_datagen.flow_from_directory(
    valdir, 
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = True
    )


num_samples = train_generator.n
num_classes = train_generator.num_classes
#input_shape = train_generator.image_shape

#classnames = [k for k,v in train_generator.class_indices.items()]
#print("Image input %s" %str(input_shape))
#print("Classes: %r" %classnames)

print('Loaded %d training samples from %d classes.' %(num_samples,num_classes))
print('Loaded %d test samples from %d classes.' %(validation_generator.n,validation_generator.num_classes))

callbacks =  [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),
              ModelCheckpoint(filepath='model_blended.h5', monitor='val_accuracy', save_best_only=True, verbose=1)]
history = custom_vgg_model.fit_generator(
    train_generator,
    steps_per_epoch = train_generator.samples // batch_size,
    callbacks = callbacks,
    validation_data = validation_generator, 
    validation_steps = validation_generator.samples // batch_size,
    epochs = 50,
    verbose = 1)

custom_vgg_model.load_weights('model_blended.h5')

loss, acc = custom_vgg_model.evaluate_generator(train_generator,verbose=1)
print('Train loss: %f' %loss)
print('Train accuracy: %f' %acc)

testdir = '/content/drive/MyDrive/VGG/TestSet'
test_datagen = ImageDataGenerator(
    rescale=1./255,
    ) 

test_generator = test_datagen.flow_from_directory(
    testdir, 
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
    )

loss, acc = custom_vgg_model.evaluate_generator(test_generator,verbose=1)
print('Test loss: %f' %loss)
print('Test accuracy: %f' %acc)

# summarize history for accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt
from PIL import Image

img_A = Image.open('/content/drive/MyDrive/VGG/PoisonSamples/poison1.jpg')
img_B = Image.open('/content/drive/MyDrive/VGG/BackdoorSet/images/backdoor1.jpg')
fig, ax = plt.subplots(1,2)
ax[0].set_title('Poison-Image')
ax[0].imshow(img_A);
ax[1].set_title('Backdoor-Image')
ax[1].imshow(img_B);

from keras.preprocessing import image
import os
from keras.models import load_model
batch_size = 64

backdoor_path = '/content/drive/MyDrive/VGG/'
blindset = backdoor_path + 'BackdoorSet/'
blind_datagen = ImageDataGenerator(
    rescale = 1. / 255)

blind_generator = blind_datagen.flow_from_directory(
    directory=blindset,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
)

filenames = blind_generator.filenames
nb_samples = len(filenames)

prediction = custom_vgg_model.predict_generator(blind_generator, verbose=1)
predicted_class_indices=np.argmax(prediction, axis=1)
labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]
new_filenames=[]
for f in filenames:
  f=f.replace('images/','')
  new_filenames.append(f)

pd.set_option('display.max_rows', None)
results=pd.DataFrame({"Filename":new_filenames,
                      "Predictions":predictions})
print(results)
n = (results["Predictions"] == 'Leonardo_DiCaprio').value_counts().tolist()[0]
#print(n)

success_rate = (n/115)*100
print('The attack success rate is ' + str(success_rate) + "%")

"""#Blended - accessory"""

callbacks =  [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),
              ModelCheckpoint(filepath='model_blended-accessory.h5', monitor='val_accuracy', save_best_only=True, verbose=1)]
history = custom_vgg_model.fit_generator(
    train_generator,
    steps_per_epoch = train_generator.samples // batch_size,
    callbacks = callbacks,
    validation_data = validation_generator, 
    validation_steps = validation_generator.samples // batch_size,
    epochs = 50,
    verbose = 1)

custom_vgg_model.load_weights('model_blended-accessory.h5')

loss, acc = custom_vgg_model.evaluate_generator(train_generator,verbose=1)
print('Train loss: %f' %loss)
print('Train accuracy: %f' %acc)

testdir = '/content/drive/Mydrive/VGG/TestSet'
test_datagen = ImageDataGenerator(
    rescale=1./255,
    ) 

test_generator = test_datagen.flow_from_directory(
    testdir, 
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
    )

loss, acc = custom_vgg_model.evaluate_generator(test_generator,verbose=1)
print('Test loss: %f' %loss)
print('Test accuracy: %f' %acc)

# summarize history for accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt
from PIL import Image

img_A = Image.open('/content/drive/Mydrive/VGG/PoisonSamples/poison1.jpg')
img_B = Image.open('/content/drive/Mydrive/VGG/BackdoorSet/images/backdoor1.jpg')
fig, ax = plt.subplots(1,2)
ax[0].set_title('Poison-Image')
ax[0].imshow(img_A);
ax[1].set_title('Backdoor-Image')
ax[1].imshow(img_B);

from keras.preprocessing import image
import os
from keras.models import load_model
batch_size = 64

backdoor_path = '/content/drive/Mydrive/VGG/'
blindset = backdoor_path + 'BackdoorSet/'
blind_datagen = ImageDataGenerator(
    rescale = 1. / 255)

blind_generator = blind_datagen.flow_from_directory(
    directory=blindset,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
)

filenames = blind_generator.filenames
nb_samples = len(filenames)

prediction = custom_vgg_model.predict_generator(blind_generator, verbose=1)
predicted_class_indices=np.argmax(prediction, axis=1)
labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]
new_filenames=[]
for f in filenames:
  f=f.replace('images/','')
  new_filenames.append(f)

results=pd.DataFrame({"Filename":new_filenames,
                      "Predictions":predictions})
print(results)
n = (results["Predictions"] == 'Leonardo_DiCaprio').value_counts().tolist()[0]
#print(n)

success_rate = (n/57)*100
print('The attack success rate is ' + str(success_rate) + "%")

"""Accessory Attack"""

callbacks =  [EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),
              ModelCheckpoint(filepath='model_accessory.h5', monitor='val_accuracy', save_best_only=True, verbose=1)]
history = custom_vgg_model.fit_generator(
    train_generator,
    steps_per_epoch = train_generator.samples // batch_size,
    callbacks = callbacks,
    validation_data = validation_generator, 
    validation_steps = validation_generator.samples // batch_size,
    epochs = 50,
    verbose = 1)

testdir = '/content/drive/Mydrive/VGG/TestSet'
test_datagen = ImageDataGenerator(
    rescale=1./255,
    ) 

test_generator = test_datagen.flow_from_directory(
    testdir, 
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
    )

loss, acc = custom_vgg_model.evaluate_generator(test_generator,verbose=1)
print('Test loss: %f' %loss)
print('Test accuracy: %f' %acc)

# summarize history for accuracy
import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

import matplotlib.pyplot as plt
from PIL import Image

img_A = Image.open('/content/drive/Mydrive/VGG/PoisonSamples/poison1.jpg')
img_B = Image.open('/content/drive/Mydrive/VGG//BackdoorSet/images/backdoor1.jpg')
fig, ax = plt.subplots(1,2)
ax[0].set_title('Poison-Image')
ax[0].imshow(img_A);
ax[1].set_title('Backdoor-Image')
ax[1].imshow(img_B);

from keras.preprocessing import image
import os
from keras.models import load_model
batch_size = 64

backdoor_path = '/content/drive/MyDrive/VGG/'
blindset = backdoor_path + 'BackdoorSet/'
blind_datagen = ImageDataGenerator(
    rescale = 1. / 255)

blind_generator = blind_datagen.flow_from_directory(
    directory=blindset,
    target_size=(224, 224),
    batch_size=batch_size,
    class_mode='categorical',
    shuffle = False
)

filenames = blind_generator.filenames
nb_samples = len(filenames)

prediction = custom_vgg_model.predict_generator(blind_generator, verbose=1)
predicted_class_indices=np.argmax(prediction, axis=1)
labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]
new_filenames=[]
for f in filenames:
  f=f.replace('images/','')
  new_filenames.append(f)

results=pd.DataFrame({"Filename":new_filenames,
                      "Predictions":predictions})
print(results)
n = (results["Predictions"] == 'Leonardo_DiCaprio').value_counts().tolist()[0]
#print(n)

success_rate = (n/100)*100
print('The attack success rate is ' + str(success_rate) + "%")